{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a62fd0cb",
   "metadata": {},
   "source": [
    "# Training the Change Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3483c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import imageio\n",
    "import collections\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import Tuple\n",
    "from shapely.geometry import Polygon\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from models.changedetection_model import ChangeDetectionModel\n",
    "\n",
    "# Import dataset that relies on synthetic_anno.json for change detection annotations\n",
    "from dataset.syntheticpairs_dataset import SyntheticPairsDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669da752",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff311c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_path = \"C:\\\\Users\\\\Ugne\\\\Documents\\\\studies\\\\Python\\\\DLGroupTask\\\\synthetic_anno.json\"\n",
    "json_file = open(annotation_path)\n",
    "anno = json.load(json_file)\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0089478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_scenes = [im[\"scene\"] for im in anno[\"images\"]]\n",
    "available_scenes_df = pd.DataFrame(available_scenes, columns=[\"scene_id\"])\n",
    "\n",
    "len(available_scenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6373f4",
   "metadata": {},
   "source": [
    "## Split into training, test, validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a42a9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scenes = len(available_scenes)\n",
    "random.seed(123)\n",
    "train_scenes = random.sample(available_scenes, int(total_scenes*0.8))\n",
    "test_scenes = random.sample([s for s in available_scenes if s not in train_scenes], int(total_scenes*0.1))\n",
    "validation_scenes = [s for s in available_scenes if s not in train_scenes+test_scenes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4c223c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_scenes_as_txt(scenes, split):\n",
    "    df = pd.DataFrame(scenes, columns=[\"scene_id\"])\n",
    "    df.to_csv(f\"imagesets\\\\{split}.txt\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "162c4c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_scenes_as_txt(train_scenes, \"train\")\n",
    "#save_scenes_as_txt(test_scenes, \"test\")\n",
    "#save_scenes_as_txt(validation_scenes, \"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9956de9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf2b0a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary defines hyperparameters for the dataset\n",
    "# Complete configurations for each experiment can be found in the configs folder\n",
    "train_set_params = {\n",
    "        \"dataset_name\": \"syntheticpairs\",\n",
    "        \"root\": \"D:\\\\DeepLearningFiles\\\\renders_multicam_diff_all\",\n",
    "        \"loader_params\": {\n",
    "            \"batch_size\": 8,\n",
    "            \"drop_last\": False,\n",
    "            \"pin_memory\": True,\n",
    "            \"num_workers\": 8\n",
    "        },\n",
    "        \"mode\": \"train\",\n",
    "        \"crop\": True,\n",
    "        \"resize\": True,\n",
    "        \"spatial_resolution\": [256, 180],\n",
    "        \"overfit\": False,\n",
    "        \"normalize\": True,\n",
    "        \"augment\": True,\n",
    "        \"shuffle\": True\n",
    "    }\n",
    "\n",
    "trainset = SyntheticPairsDataSet(train_set_params)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=train_set_params[\"loader_params\"][\"batch_size\"],\n",
    "                                          shuffle=train_set_params[\"shuffle\"], num_workers=train_set_params[\"loader_params\"][\"num_workers\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6510f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print number of batches\n",
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b684d918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ugne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ugne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights into backbone\n",
      "Number total params  39643962\n"
     ]
    }
   ],
   "source": [
    "model_params = dict({\n",
    "        \"model_name\": \"changedetection\",\n",
    "        \"num_classes\": 4,\n",
    "        \"dataset_name\": \"syntheticpairs\",\n",
    "        \"rgb\": True, # Use RGB inputs\n",
    "        \"depth\": False, # Use depth inputs\n",
    "        \"spatial_resolution\": [256, 180],\n",
    "        \"mode\": \"train\",\n",
    "        \"max_epochs\": 50, # originally set to 4000\n",
    "        \"lr\": 0.0004,\n",
    "        \"save_path\": \"/app/saved_models/changedetection_benchmark/\",\n",
    "        \"weights_path\": \"/app/saved_models/changedetection_benchmark/\",\n",
    "        \"load_weights\": -1,\n",
    "        \"val_epochs\": [1950],\n",
    "        \"val_rate\": 50,\n",
    "        \"save_rate\": 50,\n",
    "        \"lr_policy\": \"cosine\",\n",
    "        \"lr_decay_iters\": 10,\n",
    "        \"batch_size\": 16,\n",
    "        \"loss_weights\": True\n",
    "    })\n",
    "model = ChangeDetectionModel(model_params).model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db906f7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleStream(\n",
       "  (model): DeepLabV3(\n",
       "    (backbone): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): DeepLabHead(\n",
       "      (0): ASPP(\n",
       "        (convs): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ASPPConv(\n",
       "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ASPPConv(\n",
       "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (3): ASPPConv(\n",
       "            (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (4): ASPPPooling(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (project): Sequential(\n",
       "          (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (conv1): Conv2d(6, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv1_relu): ReLU()\n",
       "  (conv1_norm): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "133ff29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallelize model across GPUs if available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "# Loss definitions\n",
    "loss_weights = torch.Tensor([0.0035252888617000786, 0.33161259399877635, 0.3316452266650099, 0.3332168904745137]).cuda()\n",
    "criterion_loss = torch.nn.CrossEntropyLoss(weight=loss_weights) # Segmentation output loss\n",
    "\n",
    "# Optimizer definitions\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=model_params[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d903653",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss:  1.3090244793891908\n",
      "Epoch 1 Loss:  1.2153567337989808\n",
      "Epoch 2 Loss:  1.172402606010437\n",
      "Epoch 3 Loss:  1.1575059366226197\n",
      "Epoch 4 Loss:  1.1177576315402984\n",
      "Epoch 5 Loss:  1.0860601687431335\n",
      "Epoch 6 Loss:  1.0983562302589416\n",
      "Epoch 7 Loss:  1.0451079034805297\n",
      "Epoch 8 Loss:  1.027583167552948\n",
      "Epoch 9 Loss:  1.0147731256484986\n",
      "Epoch 10 Loss:  1.0061317873001099\n",
      "Epoch 11 Loss:  1.001140410900116\n",
      "Epoch 12 Loss:  0.9811407697200775\n",
      "Epoch 13 Loss:  0.9747023952007293\n",
      "Epoch 14 Loss:  0.9448469614982605\n",
      "Epoch 15 Loss:  0.9424292063713073\n",
      "Epoch 16 Loss:  0.9260956430435181\n",
      "Epoch 17 Loss:  0.9206092834472657\n",
      "Epoch 18 Loss:  0.8931335294246674\n",
      "Epoch 19 Loss:  0.8853948831558227\n",
      "Epoch 20 Loss:  0.9065267217159271\n",
      "Epoch 21 Loss:  0.9099127554893494\n",
      "Epoch 22 Loss:  0.893166835308075\n",
      "Epoch 23 Loss:  0.8657380020618439\n",
      "Epoch 24 Loss:  0.8511970496177673\n",
      "Epoch 25 Loss:  0.8275364065170288\n",
      "Epoch 26 Loss:  0.8512530553340912\n",
      "Epoch 27 Loss:  0.8257962715625763\n",
      "Epoch 28 Loss:  0.8405906248092652\n",
      "Epoch 29 Loss:  0.8098580551147461\n",
      "Epoch 30 Loss:  0.8452517366409302\n",
      "Epoch 31 Loss:  0.8395574283599854\n",
      "Epoch 32 Loss:  0.8176637780666351\n",
      "Epoch 33 Loss:  0.8013508802652359\n",
      "Epoch 34 Loss:  0.7837799978256226\n",
      "Epoch 35 Loss:  0.7821052432060241\n",
      "Epoch 36 Loss:  0.7971627193689347\n",
      "Epoch 37 Loss:  0.7859117615222931\n",
      "Epoch 38 Loss:  0.8329853951931\n",
      "Epoch 39 Loss:  0.7983839297294617\n",
      "Epoch 40 Loss:  0.7645381224155426\n",
      "Epoch 41 Loss:  0.7613489878177643\n",
      "Epoch 42 Loss:  0.7822401106357575\n",
      "Epoch 43 Loss:  0.7804086226224899\n",
      "Epoch 44 Loss:  0.777866051197052\n",
      "Epoch 45 Loss:  0.7370935291051864\n",
      "Epoch 46 Loss:  0.7610761058330536\n",
      "Epoch 47 Loss:  0.7744700109958649\n",
      "Epoch 48 Loss:  0.7479404020309448\n",
      "Epoch 49 Loss:  0.7787748181819916\n"
     ]
    }
   ],
   "source": [
    "# Main training loop over epochs\n",
    "starting_epoch = 0\n",
    "num_epochs = model_params['max_epochs']\n",
    "for epoch in range(starting_epoch, num_epochs):\n",
    "    train_iterations = len(trainloader)\n",
    "    train_batch_size = model_params['batch_size']\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    # Training loop over samples within epoch\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # Process data to correct types\n",
    "        img1, img2, label, scene, depth1, depth2 = data\n",
    "        img1 = img1.float()\n",
    "        img2 = img2.float()\n",
    "        depth1 = depth1.float()\n",
    "        depth2 = depth2.float()\n",
    "        label = label.type(torch.LongTensor)\n",
    "        \n",
    "        # Move data to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            img1 = img1.cuda()\n",
    "            img2 = img2.cuda()\n",
    "            depth1 = depth1.cuda()\n",
    "            depth2 = depth2.cuda()\n",
    "            label = label.cuda()\n",
    "        \n",
    "        # Get model output\n",
    "        model_input = (img1, img2, depth1, depth2)\n",
    "        model_out = model(model_input)\n",
    "        \n",
    "        # Calculate loss function, get gradients, and update network weights\n",
    "        loss = criterion_loss(model_out, label)\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(\"Epoch {} Loss: \".format(epoch), running_loss/len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71c937fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\").replace(\":\",\"\").replace(\" \",\"\").replace(\"-\",\"\")\n",
    "\n",
    "torch.save(model.state_dict(), f'change_detection_model_{current_time}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
