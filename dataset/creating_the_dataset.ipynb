{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os \n",
    "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"]=\"1\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from create_dataset_json import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"D:\\\\DeepLearningFiles\\\\renders_multicam_diff_all\"\n",
    "output_path = \"C:\\\\Users\\\\Ugne\\\\Documents\\\\studies\\\\Python\\\\DLGroupTask\\\\synthetic_anno.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_dict = dict({\"images\": [], \"annotations\": [], \"categories\": []})\n",
    "files = find_files(data_root)\n",
    "all_scenes = [get_scene_name_from_file(file, data_root) for file in files]\n",
    "\n",
    "# sampling a 100 scenes for the first attempt\n",
    "\n",
    "selected_scenes = random.sample(all_scenes, 500)\n",
    "selected_files = [file for file in files if any(scene in file[\"label1\"] for scene in selected_scenes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1860"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label1': 'D:\\\\DeepLearningFiles\\\\renders_multicam_diff_all\\\\circ.us.0000_0017c0b964c2492db349f0591c6af20a_cam-2_change-0-segmentation0001.exr', 'label2': 'D:\\\\DeepLearningFiles\\\\renders_multicam_diff_all\\\\circ.us.0000_0017c0b964c2492db349f0591c6af20a_cam-2_change-1-segmentation0001.exr', 'label': 'D:\\\\DeepLearningFiles\\\\renders_multicam_diff_all\\\\circ.us.0000_0017c0b964c2492db349f0591c6af20a_cam-2-label.png', 'label1_json': 'D:\\\\DeepLearningFiles\\\\renders_multicam_diff_all\\\\circ.us.0000_0017c0b964c2492db349f0591c6af20a_cam-2_change-0_label.json', 'label2_json': 'D:\\\\DeepLearningFiles\\\\renders_multicam_diff_all\\\\circ.us.0000_0017c0b964c2492db349f0591c6af20a_cam-2_change-1_label.json', 'bbox_json': 'D:\\\\DeepLearningFiles\\\\renders_multicam_diff_all\\\\circ.us.0000_0017c0b964c2492db349f0591c6af20a_cam-2-boxes.json'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_scene_name_from_file() missing 1 required positional argument: 'data_root'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m selected_files:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file)\n\u001b[1;32m----> 6\u001b[0m     scene_name \u001b[38;5;241m=\u001b[39m \u001b[43mget_scene_name_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# (From preprocess_synthetic_data.py)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     label_file1 \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: get_scene_name_from_file() missing 1 required positional argument: 'data_root'"
     ]
    }
   ],
   "source": [
    "\n",
    "    # i is index into images, j index into annotations, k index into categories\n",
    "    i, j, k = 0, 0, 0\n",
    "    skus = set()\n",
    "    for file in selected_files:\n",
    "        print(file)\n",
    "        scene_name = get_scene_name_from_file(file, data_root)\n",
    "        # (From preprocess_synthetic_data.py)\n",
    "        label_file1 = file[\"label1\"]\n",
    "        label_file2 = file[\"label2\"]\n",
    "        label1 = cv2.imread(label_file1, cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)[:, :, 0]\n",
    "        label2 = cv2.imread(label_file2, cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)[:, :, 0]\n",
    "        label1_json = file[\"label1_json\"]\n",
    "        with open(label1_json) as f:\n",
    "            label1_json = json.load(f)\n",
    "        label2_json = file[\"label2_json\"]\n",
    "        with open(label2_json) as f:\n",
    "            label2_json = json.load(f)\n",
    "        items1_removed = set(label1_json[\"removed_skus\"]) # Should be empty\n",
    "        items1_added = set(label1_json[\"added_skus\"]) # Should be empty\n",
    "        items2_removed = set(label2_json[\"removed_skus\"])\n",
    "        items2_added = set(label2_json[\"added_skus\"])\n",
    "        items2_shifted = set(label2_json[\"shifted_skus\"])\n",
    "        bounding_boxes = make_bbox_camogram(\n",
    "            file[\"label1_json\"], file[\"label2_json\"], file[\"label1\"], file[\"label2\"]\n",
    "        )\n",
    "        change_mask_added = np.zeros_like(label1)\n",
    "        change_mask_removed = np.zeros_like(label1)\n",
    "        change_mask_shifted = np.zeros_like(label1)\n",
    "        change_mask_added = make_masks(change_mask_added, items1_removed, label2_json, label2, \"put\")\n",
    "        change_mask_removed = make_masks(change_mask_removed, items1_added, label1_json, label1, \"take\")\n",
    "        change_mask_removed = make_masks(\n",
    "            change_mask_removed, items2_removed, label1_json, label1, \"take\"\n",
    "        )\n",
    "        change_mask_added = make_masks(change_mask_added, items2_added, label2_json, label2, \"put\")\n",
    "        change_mask_shifted = make_masks(\n",
    "            change_mask_shifted,\n",
    "            items2_shifted,\n",
    "            label1_json,\n",
    "            label1,\n",
    "            \"shift\",\n",
    "            label2_json=label2_json,\n",
    "            label2=label2,\n",
    "        )\n",
    "        change_mask = np.dstack((change_mask_removed, change_mask_added, change_mask_shifted))\n",
    "\n",
    "        # Create dict entry in images list\n",
    "        height, width = label1.shape\n",
    "        image1_name = scene_name+\"_change-0.png\"\n",
    "        image2_name = scene_name+\"_change-1.png\"\n",
    "        randommat1_name = scene_name+\"_change-0-randommats.png\"\n",
    "        randommat2_name = scene_name+\"_change-1-randommats.png\"\n",
    "        depth1_name = scene_name+\"_change-0-depth0001.exr\"\n",
    "        depth2_name = scene_name+\"_change-1-depth0001.exr\"\n",
    "        image_dict = dict({\n",
    "            \"id\": i, \n",
    "            \"license\": 1,\n",
    "            \"scene\": scene_name,\n",
    "            \"width\": width, \n",
    "            \"height\": height, \n",
    "            \"randommats1\": randommat1_name,\n",
    "            \"randommats2\": randommat2_name,\n",
    "            \"depth1\": depth1_name, \n",
    "            \"depth2\": depth2_name, \n",
    "            \"image1\": image1_name, \n",
    "            \"image2\": image2_name})\n",
    "        anno_dict[\"images\"].append(image_dict)\n",
    "\n",
    "        # Make a mask for every added SKU\n",
    "        for item in items2_added:\n",
    "            change_mask_added = np.zeros_like(label1)\n",
    "            change_mask_added = make_masks(change_mask_added, set({item}), label2_json, label2, \"put\")\n",
    "            if np.any(change_mask_added):\n",
    "                submasks = create_submask_from_array(change_mask_added)\n",
    "                for color, sub_mask in submasks.items():\n",
    "                    if item not in skus:\n",
    "                        skus.add(item)\n",
    "                        anno_dict[\"categories\"].append({\"id\": k, \"name\": item})\n",
    "                        sku_id = k\n",
    "                        k+=1\n",
    "                    else:\n",
    "                        sku_id = [d.get(\"id\") for d in anno_dict[\"categories\"] if d[\"name\"] == item][0]\n",
    "                    anno = create_sub_mask_annotation(np.array(sub_mask), image_id=i, category_id=sku_id, annotation_id=j, is_crowd=0, scene=scene_name)\n",
    "                    if anno:\n",
    "                        anno[\"action\"] = \"put\"\n",
    "                        anno_dict[\"annotations\"].append(anno)\n",
    "                        print(\"put \", sku_id)\n",
    "                        j+=1\n",
    "        # Make a mask for every removed SKU\n",
    "        for item in items2_removed:\n",
    "            change_mask_removed = np.zeros_like(label1)\n",
    "            change_mask_removed = make_masks(change_mask_removed, set({item}), label2_json, label2, \"put\")\n",
    "            if np.any(change_mask_removed):\n",
    "                submasks = create_submask_from_array(change_mask_removed)\n",
    "                for color, sub_mask in submasks.items():\n",
    "                    if item not in skus:\n",
    "                        skus.add(item)\n",
    "                        anno_dict[\"categories\"].append({\"id\": k, \"name\": item})\n",
    "                        sku_id = k\n",
    "                        k+=1\n",
    "                    else:\n",
    "                        sku_id = [d.get(\"id\") for d in anno_dict[\"categories\"] if d[\"name\"] == item][0]\n",
    "                    anno = create_sub_mask_annotation(np.array(sub_mask), image_id=i, category_id=sku_id, annotation_id=j, is_crowd=0, scene=scene_name)\n",
    "                    if anno:\n",
    "                        anno[\"action\"] = \"take\"\n",
    "                        anno_dict[\"annotations\"].append(anno)\n",
    "                        print(\"take \", sku_id)\n",
    "                        j+=1\n",
    "        # Make a mask for every shifted SKU\n",
    "        for item in items2_shifted:\n",
    "            change_mask_shifted = np.zeros_like(label1)\n",
    "            change_mask_shifted = make_masks(change_mask_shifted, set({item}), label2_json, label2, \"put\")\n",
    "            if np.any(change_mask_shifted):\n",
    "                submasks = create_submask_from_array(change_mask_shifted)\n",
    "                for color, sub_mask in submasks.items():\n",
    "                    if item not in skus:\n",
    "                        skus.add(item)\n",
    "                        anno_dict[\"categories\"].append({\"id\": k, \"name\": item})\n",
    "                        sku_id = k\n",
    "                        k+=1\n",
    "                    else:\n",
    "                        sku_id = [d.get(\"id\") for d in anno_dict[\"categories\"] if d[\"name\"] == item][0]\n",
    "                    anno = create_sub_mask_annotation(np.array(sub_mask), image_id=i, category_id=sku_id, annotation_id=j, is_crowd=0, scene=scene_name)\n",
    "                    if anno:\n",
    "                        anno[\"action\"] = \"shift\"\n",
    "                        anno_dict[\"annotations\"].append(anno)\n",
    "                        print(\"shift \", sku_id)\n",
    "                        j+=1\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_dict[\"info\"] = dict({\n",
    "        \"description\": \"Synthetic dataset created in Blender for change detection, instance segmentation, and depth estimation.\",\n",
    "        \"url\": \"https://github.com/Standard-Cognition/blender-synth\",\n",
    "        \"version\": 1,\n",
    "        \"year\": 2021,\n",
    "        \"contributor\": \"Cristina Mata, Nick Locascio, Mohammed Sheikh, Kenneth Kihara\",\n",
    "        \"date_created\": \"July 1, 2021\"\n",
    "    })\n",
    "    # Add license\n",
    "    \n",
    "anno_dict[\"licenses\"] = [dict({\n",
    "        \"url\": \"url_to_our_license\",\n",
    "        \"id\": 1,\n",
    "        \"name\": \"Attribution License\"\n",
    "    })]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path, 'w') as jsonFile:\n",
    "    json.dump(anno_dict, jsonFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
